{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semisupervised learning on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge for this project was to achieve good performance in a semi-supervised learning task on the MNIST dataset. Of the 50,000 training examples, labels are available for some small subset of 100 to 500. I predominantly focused on applying a label propagation algorithm. Below I discuss why, and how it fared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of supervised learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On review of the literature, some supervised learning approaches that featured prominently were:\n",
    "* Generative models:  (1) (2)\n",
    "* Semi-supervised support vector machines (1)\n",
    "* Self-training (2)\n",
    "* Cotraining and multiview models (1) (2)\n",
    "* Graph-based models (1) (2)\n",
    "\n",
    "In order to select one of these, my main criteria were that I wanted an algorithm with an efficient runtime that would achieve good performance with few labelled examples but very many unlablled ones. Since self-training, co-training and multiview models would usually require running classifiers over the data many times, I ruled them out. Since the label propagation approach of [Zhu and Ghahramani](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3864&rep=rep1&type=pdf) (3) has already demonstrated good performance on a digits dataset, I chose to apply it to MNIST.\n",
    "\n",
    "The algorithm used was an adapted version of the algorithm used by Zhu and Ghahramani. Since the MNIST dataset is fivefold larger than the dataset used in the original paper, it was necessary to adapt the algorithm so that it does not utilize squared distances between all datapoints. Instead, a sparse kernel was used, storing just the nearest neighbours of each datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main algorithm that was tried was label propagation. Its source of the LabelPropagation class in ../models/label_propagation.py and using five-fold cross validation, its results are demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dat/train-images-idx3-ubyte.gz\n",
      "Extracting ../dat/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dat/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dat/t10k-labels-idx1-ubyte.gz\n",
      "fold: 0 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 0 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 0 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 "
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%run '../models/label_propagation.py'\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "import json\n",
    "\n",
    "# get model\n",
    "mnist_dir = '../dat'          #the directory of mnist.ubyte files\n",
    "dat = read_data_sets(mnist_dir)\n",
    "train_sizes = [100, 300, 500]\n",
    "k_folds = 5\n",
    "\n",
    "sup_scores = np.zeros((len(train_sizes), k_folds)) # scores from using supervised knn only\n",
    "ssl_scores = np.zeros((len(train_sizes), k_folds)) # scores from using knn on propagated labels\n",
    "\n",
    "for fold in range(k_folds):\n",
    "    for j, labelled_examples in enumerate(train_sizes):\n",
    "        print('fold: {}'.format(fold), end=' ')\n",
    "        i_tr, i_unlabelled = random_sample(dat.train.labels.shape[0], labelled_examples, 3000)\n",
    "                \n",
    "        Xtr = dat.train.images[i_tr]\n",
    "        ytr = dat.train.labels[i_tr]\n",
    "        ytr_onehot = np.eye(10)[ytr]\n",
    "        Xunl = dat.train.images[i_unlabelled]\n",
    "        Xval = dat.validation.images\n",
    "        yval = dat.validation.labels\n",
    "\n",
    "        lp = LabelPropagation(n_nearest_neighbours=10, iters=20, verbose = True) #detail of this class is in ../models/label_propgation.py\n",
    "        pred = lp.propagate(Xtr, ytr_onehot, Xunl)\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "\n",
    "        knn.fit(np.vstack((Xtr,Xunl)), np.hstack((ytr, pred)))\n",
    "        ssl_scores[j, fold] = knn.score(Xval, yval)\n",
    "\n",
    "        knn.fit(Xtr, ytr)\n",
    "        sup_scores[j, fold] = knn.score(Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEhCAYAAACUW2yNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvs/qTfvRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4518245890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run '../models/label_propagation.py'\n",
    "plot_supervised_learner_performance(sup_scores, ssl_scores, title = 'Classification performance', xlab = 'Labelled examples', \n",
    "                                    ylab = 'Accuracy (zero/one loss)', ticklabs = [100,300,500], legend =['Sup', 'SSL'], ylim=(.5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we achieve better performance by optimizing the semisupervised learning scheme? To begin with, let us try a range of random plausible values for the number of nearby neighbours and for the number of iterations of label propagation used. Let us perform a random search (4) through two hyperparameters: nearby neighbours and iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_tr, i_unlabelled = random_sample(dat.train.labels.shape[0], labelled_examples, 3000)\n",
    "Xtr = dat.train.images[i_tr]\n",
    "ytr = dat.train.labels[i_tr]\n",
    "ytr_onehot = np.eye(10)[ytr]\n",
    "Xunl = dat.train.images[i_unlabelled]\n",
    "Xval = dat.validation.images\n",
    "yval = dat.validation.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_settings = 8\n",
    "\n",
    "n_neighbours_arr = np.random.random_integers(low=3, high=20, size=n_settings)\n",
    "iters_arr = np.random.random_integers(low=3, high=15, size = n_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The supervised learning score was: 0.8224\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xtr, ytr)\n",
    "sup_score = knn.score(Xval, yval)\n",
    "\n",
    "print('The supervised learning score was: {}'.format(sup_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 12, nearest neighbours: 20, accuracy 0.815, class balance: {0: 0.1, 1: 0.18, 2: 0.06, 3: 0.12, 4: 0.06, 5: 0.06, 6: 0.1, 7: 0.12, 8: 0.07, 9: 0.13}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 15, nearest neighbours: 13, accuracy 0.838, class balance: {0: 0.1, 1: 0.17, 2: 0.07, 3: 0.12, 4: 0.06, 5: 0.07, 6: 0.1, 7: 0.12, 8: 0.07, 9: 0.13}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 13, nearest neighbours: 20, accuracy 0.812, class balance: {0: 0.1, 1: 0.18, 2: 0.06, 3: 0.12, 4: 0.06, 5: 0.06, 6: 0.1, 7: 0.12, 8: 0.07, 9: 0.13}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 10, nearest neighbours: 6, accuracy 0.8736, class balance: {0: 0.1, 1: 0.15, 2: 0.08, 3: 0.11, 4: 0.07, 5: 0.08, 6: 0.1, 7: 0.11, 8: 0.08, 9: 0.13}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 3, nearest neighbours: 17, accuracy 0.8646, class balance: {0: 0.1, 1: 0.15, 2: 0.08, 3: 0.11, 4: 0.07, 5: 0.07, 6: 0.1, 7: 0.11, 8: 0.08, 9: 0.12}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 3, nearest neighbours: 13, accuracy 0.8748, class balance: {0: 0.1, 1: 0.15, 2: 0.08, 3: 0.11, 4: 0.07, 5: 0.08, 6: 0.1, 7: 0.11, 8: 0.08, 9: 0.12}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 5, nearest neighbours: 20, accuracy 0.8452, class balance: {0: 0.1, 1: 0.17, 2: 0.07, 3: 0.11, 4: 0.07, 5: 0.07, 6: 0.1, 7: 0.12, 8: 0.07, 9: 0.12}\n",
      "filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 iterations: 8, nearest neighbours: 6, accuracy 0.8766, class balance: {0: 0.1, 1: 0.14, 2: 0.08, 3: 0.11, 4: 0.07, 5: 0.08, 6: 0.1, 7: 0.11, 8: 0.08, 9: 0.13}\n",
      "the best score of 0.8766 occurred with 6 nearby neighbours and 8 iterations\n"
     ]
    }
   ],
   "source": [
    "ssl_scores = np.zeros((n_settings,))\n",
    "\n",
    "for i, (nn, iters) in enumerate(zip(n_neighbours_arr, iters_arr)):\n",
    "    lp = LabelPropagation(n_nearest_neighbours=nn, iters=iters, verbose = True)\n",
    "    yprop = lp.propagate(Xtr, np.eye(10)[ytr], Xunl)\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    knn.fit(np.vstack((Xtr,Xunl)), np.hstack((ytr, yprop)))\n",
    "    ssl_scores[i] = knn.score(Xval, yval)\n",
    "    \n",
    "    # find how popular each propagated class is:\n",
    "    class_frequencies = {i:float(\"%.2f\" % (i==yprop).mean()) for i in set(yprop)}\n",
    "    print('iterations: {}, nearest neighbours: {}, accuracy {}, class balance: {}'.format(\n",
    "            iters, nn, ssl_scores[i], class_frequencies))\n",
    "best = ssl_scores.argmax()\n",
    "print('the best score of {} occurred with {} nearby neighbours and {} iterations'.format(\n",
    "        ssl_scores.max(), n_neighbours_arr[best], iters_arr[best]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes have remained least somewhat balanced regardless of the number of iterations used. So which hyperparameter values performed best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f44bc106b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAGGCAYAAACzA6O6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQAAALZEUAUAAIAtEVQBAABgS/8fWcAxGmEaZHoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44c40a8190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2)) = plt.subplots(1, 2, sharex=False, sharey=True, figsize=(11, 6))\n",
    "\n",
    "ax1.scatter(n_neighbours_arr, ssl_scores, s=50);\n",
    "\n",
    "ax1.set_ylabel('Accuracy');\n",
    "ax1.set_xlabel('nearby_neighbours');\n",
    "\n",
    "ax2.scatter(iters_arr, ssl_scores, s=50);\n",
    "ax2.set_xlabel('iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label propagation seems to work best on average with around 4-15 nearby neighbours and 3-10 iterations.\n",
    "\n",
    "So label propagation provides a clear and significant improvement to test set classification accuracy using a K nearest neighbour classifier. But how good can our classification accuracy get using these propagated labels? To get impressive performance, we need to find the nearest neighbours across a larger portion of the dataset. This is done using stored propagated labels to save compute, though it can also be done in about an hour by uncommenting the lines from the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_examples = 100\n",
    "\n",
    "#random_perm = np.random.permutation(range(dat.train.labels.shape[0]))\n",
    "#i_tr = random_perm[:labelled_examples]\n",
    "#i_unlab = random_perm[labelled_examples:]\n",
    "\n",
    "stored_point = json.load(open('../dat/propagated_labels.json','r'))\n",
    "i_tr = np.array(stored_point['i_tr'])\n",
    "i_unlab = np.array(stored_point['i_unlab'])\n",
    "yprop = np.array(stored_point['yprop'])\n",
    "\n",
    "Xtr = dat.train.images[i_tr]\n",
    "ytr = np.eye(10)[dat.train.labels[i_tr]]\n",
    "Xunl = dat.train.images[i_unlab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lp = LabelPropagation(n_nearest_neighbours=10, iters=20, verbose = True)\n",
    "#yprop = lp.propagate(Xtr, ytr, Xunl)\n",
    "#yprop = np.eye(10)[yprop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train =np.vstack((ytr, yprop))\n",
    "x_train = np.vstack((Xtr, Xunl))\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a standard modern convolutional neural network with 4 layers, dropout, relu activations and light weight regularization, and train this on labels that were propagated using the previous technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.regularizers import WeightRegularizer\n",
    "\n",
    "def create_model(img_rows, img_cols,learning_rate, reg, decay, momentum=.9, dropout = .5):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, 5, 5, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg),\n",
    "                            input_shape=(1, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(312, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "65s - loss: 20.8670 - val_loss: 1.4048\n",
      "Epoch 2/50\n",
      "64s - loss: 11.3270 - val_loss: 0.9489\n",
      "Epoch 3/50\n",
      "64s - loss: 8.4550 - val_loss: 0.6812\n",
      "Epoch 4/50\n",
      "64s - loss: 7.0113 - val_loss: 0.5888\n",
      "Epoch 5/50\n",
      "64s - loss: 6.1942 - val_loss: 0.5387\n",
      "Epoch 6/50\n",
      "64s - loss: 5.7211 - val_loss: 0.5046\n",
      "Epoch 7/50\n",
      "64s - loss: 5.3033 - val_loss: 0.4722\n",
      "Epoch 8/50\n",
      "64s - loss: 5.1085 - val_loss: 0.5055\n",
      "Epoch 9/50\n",
      "64s - loss: 4.7926 - val_loss: 0.4617\n",
      "Epoch 10/50\n",
      "64s - loss: 4.6286 - val_loss: 0.4743\n",
      "Epoch 11/50\n",
      "64s - loss: 4.4663 - val_loss: 0.4383\n",
      "Epoch 12/50\n",
      "64s - loss: 4.2820 - val_loss: 0.4507\n",
      "Epoch 13/50\n",
      "65s - loss: 4.1994 - val_loss: 0.4283\n",
      "Epoch 14/50\n",
      "64s - loss: 4.1435 - val_loss: 0.4246\n",
      "Epoch 15/50\n",
      "64s - loss: 3.9783 - val_loss: 0.4121\n",
      "Epoch 16/50\n",
      "64s - loss: 3.9317 - val_loss: 0.4418\n",
      "Epoch 17/50\n",
      "64s - loss: 3.8893 - val_loss: 0.4655\n",
      "Epoch 18/50\n",
      "64s - loss: 3.7783 - val_loss: 0.4362\n",
      "Epoch 19/50\n",
      "64s - loss: 3.7436 - val_loss: 0.4607\n",
      "Epoch 20/50\n",
      "64s - loss: 3.7019 - val_loss: 0.4392\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "dropout = .60\n",
    "reg = 1e-6\n",
    "learning_rate = 1e-4\n",
    "decay = 1e-5\n",
    "momentum = .95\n",
    "prop_weight = .2\n",
    "\n",
    "sample_weight = np.ones((x_train.shape[0],))\n",
    "sample_weight[100:] /= prop_weight\n",
    "\n",
    "model = create_model(28, 28, learning_rate=learning_rate, reg=reg, decay = decay, dropout = dropout)\n",
    "\n",
    "x_val = dat.validation.images\n",
    "x_val = x_val.reshape(x_val.shape[0], 1, 28, 28)\n",
    "\n",
    "model.fit(x_train, np.vstack((ytr, yprop)), batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      shuffle=True, verbose=2, validation_data=(x_val, np.eye(10)[dat.validation.labels]),\n",
    "      callbacks=[EarlyStopping(monitor='val_loss', patience=4, verbose=0)],\n",
    "            sample_weight=sample_weight)\n",
    "\n",
    "x_test = dat.test.images\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "\n",
    "predictions_test = model.predict(x_test, verbose=1)\n",
    "print('Validation set accuracy: {}'.format((dat.test.labels==predictions_test.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a neural net cannot perform anywhere near this well without the propagated labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "2s - loss: 13.2731 - val_loss: 2.9490\n",
      "Epoch 2/50\n",
      "2s - loss: 13.8733 - val_loss: 2.7319\n",
      "Epoch 3/50\n",
      "2s - loss: 12.3277 - val_loss: 2.7001\n",
      "Epoch 4/50\n",
      "2s - loss: 11.9342 - val_loss: 2.7289\n",
      "Epoch 5/50\n",
      "2s - loss: 12.3815 - val_loss: 3.0577\n",
      "Epoch 6/50\n",
      "2s - loss: 12.0577 - val_loss: 3.3511\n",
      "Epoch 7/50\n",
      "2s - loss: 12.6683 - val_loss: 3.6526\n",
      "Epoch 8/50\n",
      "2s - loss: 12.3590 - val_loss: 3.7865\n",
      "10000/10000 [==============================] - 4s     \n",
      "Validation set accuracy: 0.101\n"
     ]
    }
   ],
   "source": [
    "model = create_model(28, 28, learning_rate=learning_rate, reg=reg, decay = decay, dropout = dropout)\n",
    "\n",
    "model.fit(Xtr.reshape(100,1,28,28), ytr, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=2, \n",
    "      validation_data=(dat.validation.images.reshape(dat.validation.images.shape[0],1,28,28), np.eye(10)[dat.validation.labels]),\n",
    "      callbacks=[EarlyStopping(monitor='val_loss', patience=4, verbose=0)])\n",
    "\n",
    "predictions_test = model.predict(x_test, verbose=1)\n",
    "\n",
    "print('Validation set accuracy: {}'.format((dat.test.labels==predictions_test.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main issues to remark on: \n",
    "1. Design choices for label propagation class\n",
    "2. Other approaches that were tried\n",
    "3. Other approaches that should be tried\n",
    "\n",
    "## Design choices for label propagation\n",
    "The main challenges in designing the label propagation class arose from limited computing time. The MNIST dataset contains 5x more examples than the original dataset of digits used by Zhu and Gharamani. So using a dense matrix to represent similarities between 55,000 datapoints in memory is barely possible, and performing further computations such as matrix multiplications on this matrix is infeasibly slow. Instead, it was necessary to augment Zhu and Gharamani's algorithm to use a sparse representation for similarity. A natural choice is to compute a kernel that lists the k nearest neighbours, and this is what was done. Using brute force, one would find neighbours by minimizing the squared distance between each pair of points, and this is what was done. An alternative algorithm for finding the minimum distance, the k-d tree was attempted. In theory, this gives a lookup speed of d x n x log(n) where 'd' is dimensionality and 'n' is the number of datapoints rather than d x n x n for the brute force approach. However, this did not give much significant speedup in practise and was in fact slower when 'n' was small. The label propagation algorithm was also parameterised with a number of iterations in order to give the user control of computing time and behaviour.\n",
    "\n",
    "A second design choice related to ensuring balance among the propagated classes. A difficulty with this algorithm is that if one class is propagated more widely than others, then in order to match their neighbours, many unlabelled nodes will also join that class. In order to avoid a bandwagon effect, \"class mass normalisation\" was performed (as Zhu and Ghahramani themselves proposed) so that the sum of the columns was made to equal zero, so that roughly equal amounts of each class were predicted. The accuracy is very inconsistent if class mass normalisation is not used.\n",
    "\n",
    "## Other approaches that were tried\n",
    "The main other approach that was tried was a self-training approach. Using built-in logistic regression or support vector machines, an effort was made to apply labels to all unlabelled examples in decreasing order of certainty. In the case of logistic regression, this was only able to improve performance to a few percentage points above baseline - around 76%.\n",
    "\n",
    "## Other approaches that appear worth trying\n",
    "The main approach that appears worth exploring is to train a deep model with both supervised and unsupervised training objectives from end-to-end. (5), (6) This seems to offer state-of-the-art performance presently. In particular, ladder networks have achieved an impressive error rate of only 1.06% using only 100 labelled examples, and so their approach would be worth seeking to emulate. Another approach that has served as a benchmark for this sort of problem historically is the transductive SVM, which would also be worth testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Zhu, Xiaojin. \"Semi-supervised learning.\" Encyclopedia of machine learning. Springer US, 2011. 892-897.](http://pages.cs.wisc.edu/~jerryzhu/ssl/pub/SSL_EoML.pdf)\n",
    "2. [Prakash, V. Jothi, and Dr LM Nithya. \"A survey on semi-supervised learning techniques.\" arXiv preprint arXiv:1402.4645 (2014).](http://arxiv.org/pdf/1402.4645.pdf)\n",
    "3. [Zhu, Xiaojin, and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3864&rep=rep1&type=pdf)\n",
    "4. [Bergstra, James, and Yoshua Bengio. \"Random search for hyper-parameter optimization.\" Journal of Machine Learning Research 13.Feb (2012): 281-305.](http://www.jmlr.org/papers/v13/bergstra12a.html)\n",
    "5. [Rasmus, Antti, et al. \"Semi-supervised learning with ladder networks.\" Advances in Neural Information Processing Systems. 2015.](http://papers.nips.cc/paper/5947-semi-supervised-learning-with-ladder-networks.pdf)\n",
    "6.  [Weston, Jason, et al. \"Deep learning via semi-supervised embedding.\" Neural Networks: Tricks of the Trade. Springer Berlin Heidelberg, 2012. 639-655.](https://infoscience.epfl.ch/record/192705/files/Weston_SPRINGER_2012.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
