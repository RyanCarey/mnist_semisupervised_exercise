{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dat/train-images-idx3-ubyte.gz\n",
      "Extracting ../dat/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dat/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dat/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_dir = '../dat'\n",
    "dat = read_data_sets(mnist_dir)\n",
    "train_size = 100\n",
    "sss = StratifiedShuffleSplit(dat.train.labels,train_size=train_size, \n",
    "                             test_size=dat.train.labels.shape[0]-train_size, n_iter=1, random_state = 1234)\n",
    "i_tr, i_unlab = [i for i in sss][0]\n",
    "Xtr = dat.train.images[i_tr]\n",
    "ytr = dat.train.labels[i_tr]\n",
    "Xunl = dat.train.images[i_unlab]\n",
    "yunl = dat.train.labels[i_unlab]\n",
    "Xval = dat.validation.images\n",
    "yval = dat.validation.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary discriminative CNN using propagated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.hstack((ytr, yprop))\n",
    "y_train = np.eye(10)[y_train]\n",
    "ytr_oh = np.eye(10)[ytr]\n",
    "yprop_oh = np.eye(10)[yprop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.regularizers import WeightRegularizer\n",
    "\n",
    "\n",
    "def create_model(img_rows, img_cols,learning_rate, reg, decay, momentum=.9, dropout = .5):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, 5, 5, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg),\n",
    "                            input_shape=(1, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(312, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "65s - loss: 20.2227 - val_loss: 1.1938\n",
      "Epoch 2/50\n",
      "64s - loss: 10.9600 - val_loss: 0.7252\n",
      "Epoch 3/50\n",
      "65s - loss: 8.5136 - val_loss: 0.5277\n",
      "Epoch 4/50\n",
      "64s - loss: 7.0776 - val_loss: 0.4190\n",
      "Epoch 5/50\n",
      "63s - loss: 6.2268 - val_loss: 0.3740\n",
      "Epoch 6/50\n",
      "63s - loss: 5.6243 - val_loss: 0.3132\n",
      "Epoch 7/50\n",
      "63s - loss: 5.1920 - val_loss: 0.3072\n",
      "Epoch 8/50\n",
      "63s - loss: 4.8922 - val_loss: 0.2787\n",
      "Epoch 9/50\n",
      "63s - loss: 4.6581 - val_loss: 0.2652\n",
      "Epoch 10/50\n",
      "63s - loss: 4.4685 - val_loss: 0.2587\n",
      "Epoch 11/50\n",
      "63s - loss: 4.2871 - val_loss: 0.2638\n",
      "Epoch 12/50\n",
      "63s - loss: 4.2007 - val_loss: 0.2552\n",
      "Epoch 13/50\n",
      "63s - loss: 4.0642 - val_loss: 0.2361\n",
      "Epoch 14/50\n",
      "63s - loss: 3.9798 - val_loss: 0.2329\n",
      "Epoch 15/50\n",
      "63s - loss: 3.8743 - val_loss: 0.2433\n",
      "Epoch 16/50\n",
      "63s - loss: 3.8263 - val_loss: 0.2387\n",
      "Epoch 17/50\n",
      "63s - loss: 3.7826 - val_loss: 0.2262\n",
      "Epoch 18/50\n",
      "63s - loss: 3.6875 - val_loss: 0.2337\n",
      "Epoch 19/50\n",
      "63s - loss: 3.6420 - val_loss: 0.2553\n",
      "Epoch 20/50\n",
      "63s - loss: 3.5835 - val_loss: 0.2302\n",
      "Epoch 21/50\n",
      "63s - loss: 3.5612 - val_loss: 0.2361\n",
      "Epoch 22/50\n",
      "63s - loss: 3.5293 - val_loss: 0.2361\n",
      "5000/5000 [==============================] - 2s     \n",
      "Accuracy: 0.929\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "dropout = .60\n",
    "reg = 1e-5\n",
    "learning_rate = 1e-4\n",
    "decay = 1e-5\n",
    "momentum = .95\n",
    "prop_weight = .1\n",
    "\n",
    "sample_weight = np.ones((x_train.shape[0],))\n",
    "sample_weight[train_size:] /= prop_weight\n",
    "\n",
    "model = create_model(28, 28, learning_rate=learning_rate, reg=reg, decay = decay, dropout = dropout)\n",
    "\n",
    "model.fit(x_train, np.vstack((ytr_oh, yprop_oh)), batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      shuffle=True, verbose=2, validation_data=(x_test, y_test),\n",
    "      callbacks=[EarlyStopping(monitor='val_loss', patience=4, verbose=0)],\n",
    "            sample_weight=sample_weight)\n",
    "\n",
    "predictions_valid = model.predict(x_test, verbose=1)\n",
    "\n",
    "print('Accuracy: {}'.format((y_test.argmax(axis=1)==predictions_valid.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "#doublecheck on holdout set\n",
    "x_ho = dat.test.images.reshape(dat.test.images.shape[0],1,28,28)\n",
    "predictions_test = model.predict(x_ho)\n",
    "print('Accuracy: {}'.format((dat.test.labels==predictions_test.argmax(axis=1)).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
