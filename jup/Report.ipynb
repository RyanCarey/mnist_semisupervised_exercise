{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semisupervised learning on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge for this project was to achieve good performance in a semi-supervised learning task on the MNIST dataset. Of the 50,000 training examples, labels are available for some small subset of these, between 100 and 500. The remainder are available as unlabeled images. Below, I discuss how various approaches fared, and how performance varied with different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of supervised learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On review of the literature, some supervised learning approaches that featured prominently were:\n",
    "* Generative models:  (1) (2)\n",
    "* Semi-supervised support vector machines (1)\n",
    "* Self-training (2)\n",
    "* Cotraining and multiview models (1) (2)\n",
    "* Graph-based models (1) (2)\n",
    "\n",
    "In order to select one of these, my main criteria were that I wanted an algorithm with an efficient runtime that would achieve good performance with few labelled examples but very many unlablled ones. Since self-training, co-training and multiview models would usually running classifiers over the data many times, I ruled them out. Since the label propagation approach of [Zhu and Ghahramani](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3864&rep=rep1&type=pdf) (3) has already demonstrated good performance on a digits dataset, I selected to apply it to MNIST.\n",
    "\n",
    "The algorithm used was an adapted version of the algorithm used by Zhu and Ghahramani. Since the MNIST dataset is fivefold larger than the dataset used in the original paper, it was necessary to adapt the algorithm so that it does not utilize squared distances between all datapoints. Instead, a sparse kernel was used that just stores the nearest neighbours of each datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main algorithm that was tried was label propagation. You can look over the source of the LabelPropagation class in ../models/label_propagation.py but the results are demonstrated below using five-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_sample(dataset_size, n_train, n_test, random_seed=None):\n",
    "    \"\"\"gets indices for non-overlapping training and test set samples\"\"\"\n",
    "    if (n_train + n_test) > dataset_size:\n",
    "        raise ValueError('dataset_size ({}) must be bigger than sum of n_train ({}) and n_test({})'.format(\n",
    "                dataset_size, n_train, n_test))\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.permutation(5)\n",
    "    random_perm = np.random.permutation(range(dataset_size))\n",
    "    i_train = random_perm[:n_train]\n",
    "    i_test = random_perm[(-n_test):]\n",
    "    return (i_train, i_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6, 38, 48, 21, 42, 34, 19, 22, 39, 37]), array([29, 30, 35]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample(50,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dat/train-images-idx3-ubyte.gz\n",
      "Extracting ../dat/train-labels-idx1-ubyte.gz\n",
      "Extracting ../dat/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../dat/t10k-labels-idx1-ubyte.gz\n",
      "fold: 0 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 0 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 0 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 1 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 2 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 3 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3100\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3300\n",
      "500 1000 1500 2000 2500 3000 fold: 4 filling neighbour row 1 / 3500\n",
      "500 1000 1500 2000 2500 3000 "
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%run '../models/label_propagation.py'\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "# get model\n",
    "mnist_dir = '../dat'          #the directory of mnist.ubyte files\n",
    "dat = read_data_sets(mnist_dir)\n",
    "train_sizes = [100, 300, 500]\n",
    "k_folds = 5\n",
    "\n",
    "sup_scores = np.zeros((len(train_sizes), k_folds)) # scores from using supervised knn only\n",
    "ssl_scores = np.zeros((len(train_sizes), k_folds)) # scores from using knn on propagated labels\n",
    "\n",
    "for fold in range(k_folds):\n",
    "    for j, labelled_examples in enumerate(train_sizes):\n",
    "        print('fold: {}'.format(fold), end=' ')\n",
    "            i_tr, i_unlabelled = random_sample(dat.train.labels.shape[0], labelled_examples, 3000)\n",
    "                \n",
    "        Xtr = dat.train.images[i_tr]\n",
    "        ytr = dat.train.labels[i_tr]\n",
    "        ytr_onehot = np.eye(10)[ytr]\n",
    "        Xunl = dat.train.images[i_unlabelled]\n",
    "        Xval = dat.validation.images\n",
    "        yval = dat.validation.labels\n",
    "\n",
    "        lp = LabelPropagation(n_nearest_neighbours=10, iters=20, verbose = True) #detail of this class is in ../models/label_propgation.py\n",
    "        pred = lp.propagate(Xtr, ytr_onehot, Xunl)\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "\n",
    "        knn.fit(np.vstack((Xtr,Xunl)), np.hstack((ytr, pred)))\n",
    "        ssl_scores[j, fold] = knn.score(Xval, yval)\n",
    "\n",
    "        knn.fit(Xtr, ytr)\n",
    "        sup_scores[j, fold] = knn.score(Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEhCAYAAACUW2yNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nteIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf19598450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run '../models/label_propagation.py'\n",
    "plot_supervised_learner_performance(sup_scores, ssl_scores, title = 'Classification performance', xlab = 'Labelled examples', \n",
    "                                    ylab = 'Accuracy (zero/one loss)', ticklabs = [100,300,500], legend =['Sup', 'SSL'], ylim=(.5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we achieve better performance by optimizing the semisupervised learning scheme? To begin with, let us try a range of random plausible values for the number of nearby neighbours and for the number of iterations of label propagation used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled examples = 100\n",
    "lp = LabelPropagation(n_nearest_neighbours=20, iters=20)\n",
    "lp.propagate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So label propagation provides a clear and significant improvement to test set classification accuracy using a K nearest neighbour classifier. But how good can our classification accuracy get using these propagated labels? To get impressive performance, we need to find the nearest neighbours across a larger portion of the dataset. This is done using stored propagated labels to save compute, though it can also be done in about an hour by uncommenting the lines from the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelled_examples = 100\n",
    "\n",
    "#random_perm = np.random.permutation(range(dat.train.labels.shape[0]))\n",
    "#i_tr = random_perm[:labelled_examples]\n",
    "#i_unlab = random_perm[labelled_examples:]\n",
    "\n",
    "stored_point = json.load(open('../dat/propagated_labels.json','r'))\n",
    "i_tr = np.array(stored_point['i_tr'])\n",
    "i_unlab = np.array(stored_point['i_unlab'])\n",
    "yprop = np.array(stored_point['yprop'])\n",
    "\n",
    "Xtr = dat.train.images[i_tr]\n",
    "ytr = np.eye(10)[dat.train.labels[i_tr]]\n",
    "Xunl = dat.train.images[i_unlab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling neighbour row 1 / 55000\n",
      "500 1000 1500 2000 2500 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-ce51868b7cde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_nearest_neighbours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myprop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXunl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#yprop = np.eye(10)[yprop]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/ml/mnist_ssl/models/label_propagation.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, Xtr, ytr, Xunl)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myunl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXunl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_precompute_nearest_neighbour_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXunl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_propagate_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/ml/mnist_ssl/models/label_propagation.py\u001b[0m in \u001b[0;36m_precompute_nearest_neighbour_indices\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;31m# A KDTree gives an asymptotic speedup here in theory but it's pretty slow in practise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mdists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mnearest_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_nearest_neighbours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_nearest_neighbours\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lp = LabelPropagation(n_nearest_neighbours=10, iters=20, verbose = True)\n",
    "#yprop = lp.propagate(Xtr, ytr, Xunl)\n",
    "#yprop = np.eye(10)[yprop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train =np.vstack((ytr, yprop))\n",
    "x_train = np.vstack((Xtr, Xunl))\n",
    "x_train = x_train.reshape(x_train.shape[0],1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a standard modern convolutional neural network with 4 layers, dropout, relu activations and light weight regularization, and train this on labels that were propagated using the previous technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.regularizers import WeightRegularizer\n",
    "\n",
    "def create_model(img_rows, img_cols,learning_rate, reg, decay, momentum=.9, dropout = .5):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(128, 5, 5, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg),\n",
    "                            input_shape=(1, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(312, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution2D(172, 3, 3, border_mode='same', init='he_normal', W_regularizer=WeightRegularizer(l1=reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(48))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-222caa33d5bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    406\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ryan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 50\n",
    "dropout = .60\n",
    "reg = 1e-5\n",
    "learning_rate = 1e-4\n",
    "decay = 1e-5\n",
    "momentum = .95\n",
    "prop_weight = .1\n",
    "\n",
    "sample_weight = np.ones((x_train.shape[0],))\n",
    "sample_weight[100:] /= prop_weight\n",
    "\n",
    "model = create_model(28, 28, learning_rate=learning_rate, reg=reg, decay = decay, dropout = dropout)\n",
    "\n",
    "x_val = dat.validation.images\n",
    "x_val = x_val.reshape(x_val.shape[0], 1, 28, 28)\n",
    "\n",
    "model.fit(x_train, np.vstack((ytr, yprop)), batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      shuffle=True, verbose=2, validation_data=(x_val, np.eye(10)[dat.validation.labels]),\n",
    "      callbacks=[EarlyStopping(monitor='val_loss', patience=4, verbose=0)],\n",
    "            sample_weight=sample_weight)\n",
    "\n",
    "x_test = dat.test.images\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s     \n",
      "Validation set accuracy: 0.8738\n"
     ]
    }
   ],
   "source": [
    "predictions_test = model.predict(x_test, verbose=1)\n",
    "print('Validation set accuracy: {}'.format((dat.test.labels==predictions_test.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a neural net cannot perform anywhere near this well without the propagated labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "2s - loss: 12.9856 - val_loss: 3.6905\n",
      "Epoch 2/50\n",
      "2s - loss: 12.6535 - val_loss: 3.5156\n",
      "Epoch 3/50\n",
      "2s - loss: 11.9018 - val_loss: 3.3730\n",
      "Epoch 4/50\n",
      "2s - loss: 12.8938 - val_loss: 3.2517\n",
      "Epoch 5/50\n",
      "2s - loss: 12.3144 - val_loss: 3.1902\n",
      "Epoch 6/50\n",
      "2s - loss: 11.5008 - val_loss: 3.1307\n",
      "Epoch 7/50\n",
      "2s - loss: 11.8459 - val_loss: 3.1135\n",
      "Epoch 8/50\n",
      "2s - loss: 11.5147 - val_loss: 3.1385\n",
      "Epoch 9/50\n",
      "2s - loss: 12.4657 - val_loss: 3.0912\n",
      "Epoch 10/50\n",
      "2s - loss: 11.8254 - val_loss: 3.0902\n",
      "Epoch 11/50\n",
      "2s - loss: 12.1657 - val_loss: 3.0668\n",
      "Epoch 12/50\n",
      "2s - loss: 12.1248 - val_loss: 3.0205\n",
      "Epoch 13/50\n",
      "2s - loss: 10.9505 - val_loss: 2.7803\n",
      "Epoch 14/50\n",
      "2s - loss: 11.2944 - val_loss: 2.6577\n",
      "Epoch 15/50\n",
      "2s - loss: 11.1511 - val_loss: 2.5990\n",
      "Epoch 16/50\n",
      "2s - loss: 10.2611 - val_loss: 2.5296\n",
      "Epoch 17/50\n",
      "2s - loss: 11.4827 - val_loss: 2.4749\n",
      "Epoch 18/50\n",
      "2s - loss: 10.1019 - val_loss: 2.3999\n",
      "Epoch 19/50\n",
      "2s - loss: 10.0221 - val_loss: 2.3815\n",
      "Epoch 20/50\n",
      "2s - loss: 10.5887 - val_loss: 2.3959\n",
      "Epoch 21/50\n",
      "2s - loss: 10.7218 - val_loss: 2.3608\n",
      "Epoch 22/50\n",
      "2s - loss: 9.5908 - val_loss: 2.3357\n",
      "Epoch 23/50\n",
      "2s - loss: 9.2224 - val_loss: 2.3465\n",
      "Epoch 24/50\n",
      "2s - loss: 9.7187 - val_loss: 2.3421\n",
      "Epoch 25/50\n",
      "2s - loss: 9.3187 - val_loss: 2.3080\n",
      "Epoch 26/50\n",
      "2s - loss: 9.1696 - val_loss: 2.2732\n",
      "Epoch 27/50\n",
      "2s - loss: 8.9951 - val_loss: 2.2548\n",
      "Epoch 28/50\n",
      "2s - loss: 7.0350 - val_loss: 2.2611\n",
      "Epoch 29/50\n",
      "2s - loss: 8.3874 - val_loss: 2.2674\n",
      "Epoch 30/50\n",
      "2s - loss: 8.0697 - val_loss: 2.2715\n",
      "Epoch 31/50\n",
      "2s - loss: 6.6899 - val_loss: 2.2701\n",
      "Epoch 32/50\n",
      "2s - loss: 7.2295 - val_loss: 2.2662\n",
      "10000/10000 [==============================] - 4s     \n",
      "Validation set accuracy: 0.1171\n"
     ]
    }
   ],
   "source": [
    "model = create_model(28, 28, learning_rate=learning_rate, reg=reg, decay = decay, dropout = dropout)\n",
    "\n",
    "model.fit(Xtr.reshape(100,1,28,28), ytr, batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=2, \n",
    "      validation_data=(dat.validation.images.reshape(dat.validation.images.shape[0],1,28,28), np.eye(10)[dat.validation.labels]),\n",
    "      callbacks=[EarlyStopping(monitor='val_loss', patience=4, verbose=0)])\n",
    "\n",
    "predictions_test = model.predict(x_test, verbose=1)\n",
    "\n",
    "print('Validation set accuracy: {}'.format((dat.test.labels==predictions_test.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main issues to remark on: \n",
    "1. Design choices for label propagation class\n",
    "2. Other approaches that were tried\n",
    "3. Other approaches that should be tried\n",
    "\n",
    "## Design choices for label propagation\n",
    "The main challenges in designing the label propagation class arose from limited computing time. The MNIST dataset contains 5x more examples than the original dataset of digits used by Zhu and Gharamani. So using a dense matrix to represent similarities between 55,000 datapoints, and storing these in memory is barely feasible, and performing further computations such as matrix multiplications on this is infeasibly slow. Instead, it was necessary to augment Zhu and Gharamani's algorithm to use a sparse representation for similarity. A natural choice is to compute a kernel that lists the k nearest neighbours, and this is what was done. The K nearest neighbours could be computed using a k-d tree without computing all of the distances, giving a lookup speed of d x n x log(n) where 'd' is dimensionality and 'n' is the number of datapoints rather than d x n x n for the brute force approach, but this did not give much significant speedup in practise and was in fact slower when 'n' was small. Also for reasons of limited computing time, the label propagation algorithm was parameterised with a number of iterations rather than running to convergence.\n",
    "\n",
    "A second design choice related to ensuring balance among the propagated classes. A difficulty with this algorithm is that if one class is propagated more widely than others, then in order to match their neighbours, many unlabelled nodes will also join that class. In order to avoid these bandwagon effects, \"class mass normalisation\" was performed so that the sum of the columns was made to equal zero, so that roughly equal amounts of each class were predicted. The accuracy is very inconsistent if class mass normalisation is not used.\n",
    "\n",
    "## Other approaches that were tried\n",
    "The main other approach that was tried was a self-training approach. Using built-in logistic regression and support vector machines, an effort was made to apply labels to all unlabelled examples in decreasing order of certainty. In the case of logistic regression, this was only able to improve performance by a few percentage points, to around 76%.\n",
    "\n",
    "## Other approaches that appear worth trying\n",
    "One approach that has served as a benchmark for this sort of problem, and therefore seems worth trying, is the transductive SVM. However, currently, the state of the art in unsupervised image classification algorithms appears to use deep learning models from end-to-end [4], [5]. In particular, ladder networks have achieved an impressive error rate of only 1.06% using only 100 labelled examples, and so their approach would be worth seeking to emulate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Zhu, Xiaojin. \"Semi-supervised learning.\" Encyclopedia of machine learning. Springer US, 2011. 892-897.](http://pages.cs.wisc.edu/~jerryzhu/ssl/pub/SSL_EoML.pdf)\n",
    "2. [Prakash, V. Jothi, and Dr LM Nithya. \"A survey on semi-supervised learning techniques.\" arXiv preprint arXiv:1402.4645 (2014).](http://arxiv.org/pdf/1402.4645.pdf)\n",
    "3. [Zhu, Xiaojin, and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.3864&rep=rep1&type=pdf)\n",
    "4. [Rasmus, Antti, et al. \"Semi-supervised learning with ladder networks.\" Advances in Neural Information Processing Systems. 2015.](http://papers.nips.cc/paper/5947-semi-supervised-learning-with-ladder-networks.pdf)\n",
    "5.  [Weston, Jason, et al. \"Deep learning via semi-supervised embedding.\" Neural Networks: Tricks of the Trade. Springer Berlin Heidelberg, 2012. 639-655.](https://infoscience.epfl.ch/record/192705/files/Weston_SPRINGER_2012.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
